{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143d428c",
   "metadata": {},
   "source": [
    "# Überwachtes Lernen\n",
    "Bestimmung einer Funktion zur Vorhersage von Merkmalen (Nominal/Ordinal/Kardinal) unter Verwendung von vollständigen Trainingsdaten (training-set). Nach ihrer Bestimmung wird die Funktion anhand weiterer Daten getestet (testing-set).\n",
    "\n",
    "### Klassifizierung\n",
    "Alle vor dem Lernprozess verfügbaren Daten liegen kategorisiert vor. Jeder Datenpunkt besteht aus Merkmalen (Kovariablen) und einer zugeordneten Kategorie. Ziel der Klassifizierung ist eine Funktion abzuleiten, welche neue Daten der gegebenen Menge von Kategorien zuordnet. Die zur Bestimmung der Funktion verwendeten Trainingsdaten bestehen je aus einem Eingangsvektor und dem gewünschten Rückgabewert (Überwachungssignal). Eine weitere Generalisierung hat zum Ziel vollständig unbekannte Datenpunkte einer passenden Kategorie zuzuordnen. \n",
    "\n",
    "### Regression\n",
    "Anstelle den Daten zugeordnete Kategorien liegen kontinuierliche Ausgangsgrößen (abhängige Variablen) vor. Ziel ist die Erstellung einer Schätzfunktion mit kontinuierlichem Wertebereich. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5003a0fb",
   "metadata": {},
   "source": [
    "# Lineare Modelle\n",
    "Umfassen Methoden zur Datenmodellierung mittels linearer Regression. Der vorhergesagte Zielwert $y$ (target) wird durch eine Linearkombination aller gegebenen Merkmale (features) berechnet:\n",
    "\n",
    "$$y(w,x)=w_{0}+w_{1}x_{1}+...+w_{n}x_{n}$$\n",
    "\n",
    "Vektor $\\vec{x}=(x_{1},..,x_{n})$ enthält die Merkmalswerte und Vektor $\\vec{w}=(w_{0},w_{1},..,w_{n})$ enthält die Regressionskoeffizienten. Die Schätzung der Regressionskoeffizienten setzt die Unabhängigkeit aller Merkmale in $\\vec{x}$ voraus. Ist diese Voraussetzung nicht erfüllt, ist eine hohe Modellvarianz die Folge (Schon durch kleine Schwankungen der Zielwerte, z.B. durch zufällige Fehler, entstehen große Abweichungen innerhalb der Regressionskoeffizienten.)\n",
    "\n",
    "Das Beispiel im folgenden Bild enthält beobachtete Punkte und ihre Approximation mit einem linearen Modell. Die Approximation erfolgt durch die Minimierung der RSS (residual sum of sqaures) zwischen den vorhandenen Daten und den vorhergesagten Daten. (Klasse: sklearn.linear_model.LinearRegression) \n",
    "<img src=\"Lineares_Modell.png\" style=\"width: 400px; height: 300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5f25a",
   "metadata": {},
   "source": [
    "### Polynomiale Regression nichtlinearer Daten\n",
    "Lineare Modelle (Schätzer) lassen sich durch polynomiale Regression auch auf nichtlineare Abbildungen von Daten anwenden. Dabei wird der Merkmalbereich um  interagierende oder potenzierte Merkmale erweitert, denen jeweils ein neuer linearer Regressionskoeffizient zugeordnet wird.\n",
    "\n",
    "Ein ebenes lineares Modell könnte folgendermaßen aussehen:\n",
    "\n",
    "$$y(w,x)=w_{0}+w_{1}x_{1}+w_{2}x_{2}$$\n",
    "\n",
    "Durch eine entsprechende lineare Modellerweiterung (Transformierung) nimmt das Modell die Form eines Paraboloids an:\n",
    "\n",
    "$$y(w,x)=w_{0}+w_{1}x_{1}+w_{2}x_{2}+w_{3}x_{1}x_{2}+w_{4}x_{1}^{2}+w_{5}x_{2}^{2}$$\n",
    "\n",
    "Eine Neubenennung der Merkmale verdeutlicht, dass sich dieses Modell mit den Methoden der linearen Modellierung an die Trainingsdaten anpassen lässt:\n",
    "\n",
    "$$y(w,x)=w_{0}+w_{1}z_{1}+w_{2}z_{2}+w_{3}z_{3}+w_{4}z_{4}+w_{5}z_{5},$$\n",
    "\n",
    "mit$$\\vec{z}=(x_{1},x_{2},x_{1}x_{2},x_{1}^{2},x_{2}^{2}).$$\n",
    "\n",
    "Im folgenden Bild ist die polynomiale Regression eindimensionaler Daten in Abhängigkeit des Erweiterungsgrades dargestellt. \n",
    "(Klassen: sklearn.preprocessing.PolynomialFeatures und sklearn.linear_model.LinearRegression) \n",
    "<img src=\"Polynomiale_Modelle.png\" style=\"width: 400px; height: 300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47770201",
   "metadata": {},
   "source": [
    "***\n",
    "### Einfluss des Grades der polynomialen Regression auf die lineare Modellierung\n",
    "Zur Verdeutlichung des Einflusses, welchen polynomial erzeugte Merkmale und ihr höchster Grad auf ein berechnetes Modell haben, wird zunächst einmal eine nichtpolynomiale lineare Regression von sinusförmig verteilten Daten durchgeführt.\n",
    "\n",
    "Zu Beginn werden die der Modellierung zugrunde liegenden Daten erzeugt. Das Merkmal X enthält zufällige Punkte (samples) zwischen $0$ und $2\\pi$. Die abhängige Variable Y erhält man durch die Anwendung der Sinusfunktion auf die Definitionsmenge. Die erzeugten Daten sind somit unsortiert, aber haben eine feste Reihenfolge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4c0ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "X = [random.random()*2*np.pi for i in range(50)]\n",
    "Y_sin = [np.sin(element) for element in X]\n",
    "for i in range(40,50): #Es werden zur Veranschaulichung 10 Datenpunkte ausgegeben\n",
    "    print('X{0:<3} {1:<10.2f} Y{0:<3} {2:>5.2f}'.format(i, X[i], Y_sin[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e07a9",
   "metadata": {},
   "source": [
    "Im Plot sehen die Daten folgendermaßen aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67500d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title('Elements given by the sinus function', fontsize=10)\n",
    "plt.xlim([-np.pi/2,np.pi*5/2])\n",
    "plt.ylim([-1.5,1.5])\n",
    "plt.scatter(X,Y_sin,label='target_values',s=5)\n",
    "plt.legend(loc='lower left')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d7619",
   "metadata": {},
   "source": [
    "Um die Daten zum überwachten Lernen einzusetzen müssen sie zunächst in Trainings- und Testdaten unterteilt und in Matrixform (n_samples $\\times$ n_features/n_targets) gebracht werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training_features = np.array(X[:-25])[:,np.newaxis] #25 samples/1 feature\n",
    "testing_features = np.array(X[-25:])[:,np.newaxis]\n",
    "training_targets = np.array(Y_sin[:-25])[:,np.newaxis]\n",
    "testing_targets = np.array(Y_sin[-25:])[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217c429",
   "metadata": {},
   "source": [
    "Anhand der Trainigsdaten führen wir anschließend eine einfache Regressionsanalyse durch und fertigen ein lineares Modell an. Dafür verwenden wir das Modul \"sklearn.linear_model\" und erzeugen eine Instanz vom Typ \"LinearRegression\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad3a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d4eab",
   "metadata": {},
   "source": [
    "Das untrainierte Modell kann nun an die Trainingsdaten angepasst werden. Das Resultat ist eine Schätzfunktion mit fixen Regressionskoeffienten und wird \"predictor\" genannt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(training_features,training_targets)\n",
    "\n",
    "print('{string:<25} {n_feat}'.format(string = 'Anzahl der Merkmale', n_feat = reg.n_features_in_))\n",
    "print('{string:<25} {coef}'.format(string = 'Koeffizienten', coef = reg.coef_))\n",
    "print('{string:<25} {inter}'.format(string = 'Achsenabschnitt', inter = reg.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f297ab9",
   "metadata": {},
   "source": [
    "Mit dem trainierten Modell können nun anhand der Testdaten Vorhersagen gemacht werden, welche mit den wahren Zielwerten (testing_targets) verglichen werden können. Zur Einschätzung der Vorhersagekraft werden die Ergebnisse geplottet und die mittlere quadratische Abweichung (MSE, kleiner ist besser) zwischen den vorhergesagten Zielwerten und den wahren Zielwerten sowie das Bestimmtheitsmaß $R^2$ (1 ist optimal) berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45bb5e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE, r2_score as r2\n",
    "\n",
    "predicted_targets = reg.predict(testing_features)\n",
    "\n",
    "print('{string:<25} {MSE:.2f}'.format(string = 'MSE', MSE = MSE(testing_targets, predicted_targets)))\n",
    "print('{string:<25} {R2:.2f}'.format(string = 'R2', R2 = r2(testing_targets, predicted_targets)))\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title('Prediction with testing data', fontsize=10)\n",
    "plt.xlim([-np.pi/2,np.pi*5/2])\n",
    "plt.ylim([-1.5,1.5])\n",
    "plt.scatter(testing_features,testing_targets,label='testing_targets',s=5)\n",
    "plt.scatter(testing_features,predicted_targets,label='predicted_targets',color='red',s=5)\n",
    "plt.legend(loc='lower left')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d427a94",
   "metadata": {},
   "source": [
    "Die Vorhersagekraft des nichtpolynomial erzeugten Modells ist nicht hoch. Um die Vorhersagekraft zu optimieren werden im Folgenden polynome Merkmale mittels eines Transformators ergänzt und die Fähigkeit zur Schätzung der Zielwerte in Abhängigkeit vom Erweiterungsgrad überwacht.\n",
    "***\n",
    "Der Transformator erzeugt mit den Daten der vorherigen Trainingsmatrix eine neue Trainingsmatrix, welche zusätzlich zu den alten Merkmalen neu errechnete Merkmale höheren Grades enthält. Der höchste Grad wird im Vorfeld bei der Instanziierung des neuen Transformationsobjekts definiert (es ist aber auch möglich ausschließlich Interaktionen der Merkmale zu berücksichtigen). \n",
    "\n",
    "Mit den neuen Trainingsdaten kann anschließend ein einfaches lineares Modell mit einer linearen Regression an die Trainingsdaten angepasst werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c995e0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly2 = PolynomialFeatures(degree=2, include_bias=False) #Erzeugen des Transformators\n",
    "poly2.fit(training_features) \n",
    "poly2_training_features = poly2.transform(training_features) \n",
    "poly2_testing_features = poly2.transform(testing_features) \n",
    "\n",
    "print('{string:<25} {n_feat}'.format(string = 'Merkmale vorher', n_feat = poly2.n_features_in_))\n",
    "print('{string:<25} {n_feat}\\n'.format(string = 'Merkmale nachher', n_feat = poly2.n_output_features_))\n",
    "print(poly2_training_features[-10:,:]) #Es werden zur Veranschaulichung 10 Datenpunkte ausgegeben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd1fb6",
   "metadata": {},
   "source": [
    "Nun kann wie bereits oben vorgeführt eine neue lineare Regression anhand der gewonnenen polynomen Traningsdaten durchgeführt werden. Anschließend benutzen wir das neue Modell um Vorhersagen zu machen und diese mit den ebenfalls polynomisierten Testdaten zu vergleichen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ac47e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "poly2_reg = linear_model.LinearRegression()\n",
    "poly2_reg.fit(poly2_training_features,training_targets)\n",
    "\n",
    "print('{string:<25} {n_feat}'.format(string = 'Anzahl Regr. Merkmale', n_feat = poly2_reg.n_features_in_))\n",
    "print('{string:<25} {coef}'.format(string = 'Regr. Koeffizienten', coef = poly2_reg.coef_))\n",
    "print('{string:<25} {inter}\\n'.format(string = 'Achsenabschnitt', inter = poly2_reg.intercept_))\n",
    "\n",
    "#Vorhersage und Überprüfung\n",
    "predicted_targets = poly2_reg.predict(poly2_testing_features)\n",
    "\n",
    "print('{string:<25} {MSE:.2f}'.format(string = 'MSE', MSE = MSE(testing_targets, predicted_targets)))\n",
    "print('{string:<25} {R2:.2f}'.format(string = 'R2', R2 = r2(testing_targets, predicted_targets)))\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title('Testing data, degree 2', fontsize=10)\n",
    "plt.xlim([-np.pi/2,np.pi*5/2])\n",
    "plt.ylim([-1.5,1.5])\n",
    "plt.scatter(testing_features,testing_targets,label='testing_targets',s=5)\n",
    "plt.scatter(testing_features,predicted_targets,label='predicted_targets',color='red',s=5)\n",
    "plt.legend(loc='lower left')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa49334",
   "metadata": {},
   "source": [
    "Das angepasste Modell mit Grad 2 hat nun einen quadratischen Verlauf, schneidet aber bei der Validierung mit den Testdaten nicht in jedem Fall besser ab (Erkennbar an der Anpassungsgüte). Das liegt daran, dass das Modell ausschließlich auf den Trainingsdaten beruht.\n",
    "***\n",
    "Eine Vorhersage mit den Trainingsdaten selbst ist auch möglich. Auch diese Vorhersage lässt sich bewerten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vorhersage und Überprüfung\n",
    "predicted_training_targets = poly2_reg.predict(poly2_training_features)\n",
    "\n",
    "print('{string:<25} {MSE:.2f}'.format(string = 'MSE', MSE = MSE(training_targets, predicted_training_targets)))\n",
    "print('{string:<25} {R2:.2f}'.format(string = 'R2', R2 = r2(training_targets, predicted_training_targets)))\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title('Training data, degree 2', fontsize=10)\n",
    "plt.xlim([-np.pi/2,np.pi*5/2])\n",
    "plt.ylim([-1.5,1.5])\n",
    "plt.scatter(training_features,training_targets,label='training_targets',s=5)\n",
    "plt.scatter(training_features,predicted_training_targets,label='predicted_training_targets',color='red',s=5)\n",
    "plt.legend(loc='lower left')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70860c",
   "metadata": {},
   "source": [
    "***\n",
    "Mittels einer selbst erstellten Funktion, welche alle oben genannten Schritte mit einbezieht, lässt sich dieser Prozess einfacher Visualisieren. \n",
    "\n",
    "Anhand der Trainingsdsaten wird, genau wie oben bereits dargestellt, erst eine Polynomisierung und anschließend eine lineare Regression mit dem erweiterten Merkmalsbereich durchgeführt. Die Auswertung der Vorhersagegüte erfolgt auf Basis der übrigen Testdaten. Darüber hinaus wird das vollständige Modell und sein Grad ausgegeben.\n",
    "\n",
    "Wir wiederholen die vorangegangenen Schritte in einem kurzen Schritt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc426a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1455e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polypredictmodule import polypredict\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "plot = polypredict(ax, np.sin, samples_X=X, samples_Y=Y_sin, degree=2, show_predicted_targets=True) #Auswertung der Sinus-Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a63b8ab",
   "metadata": {},
   "source": [
    "Dargestellt sind die zu schätzende Funktion mit den Zielwerten der Trainings- und Testdaten und die Schätzfunktion.\n",
    "***\n",
    "Durch die Erhöhung des Grades erhöhen wir die Anpassung an die Trainingsdaten. \n",
    "\n",
    "Im Folgenden wird zu allen Daten eine normalverteilte Streuung ergänzt, wie sie auch bei real gemessenen Daten auftritt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227ee9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_sin_rand = [element+(0.3*abs(max(Y_sin, key=abs))*np.random.normal(0, 0.2)) for element in Y_sin]\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "plot = polypredict(ax, np.sin, samples_X=X, samples_Y=Y_sin_rand, degree=3, show_predicted_targets=True) #Auswertung der Sinus-Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eab113",
   "metadata": {},
   "source": [
    "Die Anpassungsgüte ist mit Polynomgrad 3 bereits sehr hoch. Dies wird durch den MSE und $R^2$ Wert bestätigt. Eine weitere Erhöhung des Grades optimiert die Anpassung an die Trainingsdaten immer weiter. Mit Grad 5 ergibt sich mit den gleichen Daten folgende Modellierung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07543fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from polypredictmodule import polypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365fa5a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "plot = polypredict(ax, np.sin, samples_X=X, samples_Y=Y_sin_rand, degree=5, show_predicted_targets=True) #Auswertung der Sinus-Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35790b28",
   "metadata": {},
   "source": [
    "### Overfitting und Underfitting\n",
    "Welche Auswirkung der Polynomgrad auf die Modellierung und die Vorhersagegüte hat, wird im Folgenden Beispiel gezeigt.\n",
    "\n",
    "Anstelle der Sinus-Funktion können auch andere Funktionen modelliert werden. Zum Beispiel ein beliebiges Polynom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial(x):\n",
    "    P = [1, -5, -3, 2, 1] #Absteigende Liste von Koeffizienten für ein Polynom mit Grad len(P)-1\n",
    "    y = np.polyval(P,x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba9c7b1",
   "metadata": {},
   "source": [
    "Mit dem Polynom werden zuerst neue Trainings- und Testdaten erzeugt. Anschließend werden Schätzfunktionen mit unterschiedlichem Grad bestimmt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94917d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = [random.random()*2*np.pi for i in range(50)] #Erzeugen neuer Daten\n",
    "Y2_poly= [polynomial(element) for element in X2]\n",
    "Y2_poly_rand = [element+(0.3*abs(max(Y2_poly, key=abs))*np.random.normal(0, 0.2)) for element in Y2_poly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89ad57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "ax.set_ylim(min(Y2_poly_rand)*1.1,max(Y2_poly_rand)*1.1)\n",
    "plot = polypredict(ax, polynomial, samples_X=X2, samples_Y=Y2_poly_rand, degree=2) \n",
    "for i in [6,30]:\n",
    "    plot = polypredict(ax, polynomial, samples_X=X2, samples_Y=Y2_poly_rand, degree=i, figure=fig, show_given_function=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769717d0",
   "metadata": {},
   "source": [
    "Es zeigt sich, dass eine Vergrößerung des Polynomgrades nur bis zu einem bestimmten Wert Sinn macht. Ein Optimum scheint bei Grad 6 zu liegen. Bei Grad 30 ist die Vorhersagekraft für Bereiche zwischen den Traningspunkten deutlich verschlechtert. Diese Beobachtungen werden durch den MSE-Wert und dem Maß für die Anpassungsgüte $R^2$ bestätigt.\n",
    "\n",
    "Dieses Verhalten wird \"Overfitting\" genannt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9bb47a",
   "metadata": {},
   "source": [
    "Im Allgemeinen steigt mit Erhöhung des Grades die Anpassung an die Trainingsdaten, aber die Vorhersagekraft für die Testdaten fällt mit steigendem Grad irgendwann wieder ab. \n",
    "\n",
    "Um das zu verdeutlichen werden im Folgenden sowohl auf Basis von Trainingsdaten als auch auf Grundlage von Testdaten Vorhersagen gemacht. Die Auswertung erfolgt mit dem MSE-Wert und der Anpassungsgüte $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb314908",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = [random.random()*2*np.pi for i in range(50)]\n",
    "Y3_poly= [polynomial(element) for element in X3]\n",
    "Y3_poly_rand = [element+(0.3*abs(max(Y3_poly, key=abs))*np.random.normal(0, 0.2)) for element in Y3_poly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b45cca7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from polypredictmodule import R2MSEeval\n",
    "R2MSEeval(maximum_degree=12, samples_X=X3, samples_Y=Y3_poly_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fdc594",
   "metadata": {},
   "source": [
    "Wie der MSE Wert und die Anpassungsgüte $R^2$ zeigen, wird der Anpassungsfehler bei den Trainingsdaten mit steigendem Grad immer kleiner, aber die Vorhersagekraft bei den Testdaten nimmt mit steigendem Grad irgendwann wieder ab. \n",
    "\n",
    "### Bias vs. Variance\n",
    "\n",
    "Im letzten Beispiel sieht man sehr gut, dass mit steigender Modellkomplexität die Anpassung an das Modell optimaler wird (kleinerer Bias), aber im Gegensatz dazu die Vorhersagekraft stark abnimmt (höhere Modellvarianz). Bei zu geringer Komplexität ist die Anpassung des Modells an die Trainingsdaten schlecht, woraus auch eine schlechte Vorhersagekraft resultiert. Es gilt daher ein ausgewogenes Maß bei der Annäherung an die Trainingsdaten während der Modellierung zu finden.\n",
    "\n",
    "<img src=\"Bias_Variance_Trade Off.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5145cf2b",
   "metadata": {},
   "source": [
    "### Lasso\n",
    "Das Lasso ist ein lineares Modell, das Koeffizienten schätzt und dabei die Tendenz hat insgesamt weniger Koeffizienten zu verwenden. Dadurch wird die Anzahl abhängiger Merkmale reduziert. Die Formel zur Fehlerminimierung zur Bestimmung der Koeffizienten umfasst einen weiteren angehängten Term. Die Höhe von Alpha bestimmt wie schnell Koeffizienten vernachlässigt werden. \n",
    "\n",
    "$$\\min_{w} { \\frac{1}{2n_{\\text{samples}}} ||X w - y||_2 ^ 2 + \\alpha ||w||_1}$$\n",
    "\n",
    "Die Schwierigkeit besteht darin Alpha so zu optimieren, dass das Modell die zugrunde liegenden Daten mit optimalem \"Grad der Generalisierung\" und Varianz wiedergibt.\n",
    "Als Kriterium kommen der resultierende MSE-Wert (mean squared error) oder sogenannte Informationskriterien wie das Akaike information criterion (AIC) oder das Bayes information criterion (BIC) in Frage. \n",
    "\n",
    "Im Folgenden Beispiel wird Alpha anhand des MSE-Werts optimiert. Mit definierten Werten von Alpha werden Modelle bestimmt. Das beste Modell wird mit k-facher Cross-Validierung ausgewählt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes #Laden von Beispieldaten\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b64653",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_of_cross_validations = 5\n",
    "alpha_values = [0.01, 0.02, 0.03, 0.05, 0.07, 0.08, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "reg = LassoCV(alphas=alpha_values,cv=number_of_cross_validations, random_state=0).fit(X_train, y_train)\n",
    "print('gewähltes Alpha   '+str(reg.alpha_))\n",
    "print('R2 Trainingsdaten '+str(reg.score(X_train, y_train)))\n",
    "print('R2 Testdaten      '+str(reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e8bb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28407337",
   "metadata": {},
   "source": [
    "### K-fache Cross-Validierung\n",
    "\n",
    "Um Overfitting zu vermeiden gibt es die Strategie der Cross-Validierung. Damit soll eine möglichst hohe Generalisierung sichergestellt werden. Jede Art von Wissen über die Daten kann schon bei der Selektion von sogenannten \"Hyperparametern\" (externe Konfigurationsvariablen) die Modellierung beeinflussen. Um diesen Effekt zu minimiern wird das Trainings-Set unterteilt und ein Validierungs-Set erzeugt. Mit dem Validierungs-Set erfolgt eine Vorbewertung des Modells und somit der Hyperparameter. Nach der Modellierung wird das Modell wie gehabt mit den Test-Daten überprüft. \n",
    "\n",
    "Durch die weitere Unterteilung senkt sich aber wiederum die Anzahl der verfügbaren Stichproben und das Modell könnte an Aussagekraft verlieren. Die Auswahl der Daten hätte einen zufälligen Einfluss auf das Modell. \n",
    "\n",
    "Bei der k-fachen Cross-Validierung wird dieses Problem umgangen, indem die Trainingsdaten in k kleinere Datensätze unterteilt werden. Anschließend werden k Schritte durchlaufen, welche immer den gleichen Ablauf haben: Ein Modell wird anhand von k-1 Trainingdatensätzen erstellt und mit dem übrigen Datensatz validiert (seine Performance bestimmt). Der Durchschnitt aller k Validierungen ergibt die Gesamtperformance. \n",
    "\n",
    "<img src=\"k-fache_Cross_Validierung.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f66a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
